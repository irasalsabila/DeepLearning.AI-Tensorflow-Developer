{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOoyQ70H00_s"
      },
      "source": [
        "## Exercise 2\n",
        "In the course you learned how to do classification using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
        "\n",
        "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
        "\n",
        "Some notes:\n",
        "1. It should succeed in less than 10 epochs, so it is okay to change epochs to 10, but nothing larger\n",
        "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
        "3. If you add any additional variables, make sure you use the same names as the ones used in the class\n",
        "\n",
        "I've started the code for you below -- how would you finish it? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tMRHJl7WNlMJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow import keras"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load and inspect the data\n",
        "\n",
        "Begin by loading the data. A couple of things to notice:\n",
        "\n",
        "- The file mnist.npz is already included in the current workspace under the data directory. By default the load_data from Keras accepts a path relative to ~/.keras/datasets but in this case it is stored somewhere else, as a result of this, you need to specify the full path.\n",
        "\n",
        "- load_data returns the train and test sets in the form of the tuples (x_train, y_train), (x_test, y_test) but in this exercise you will be needing only the train set so you can ignore the second tuple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data\n",
        "\n",
        "# Get current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Append data/mnist.npz to the previous path to get the full path\n",
        "data_path = os.path.join(current_dir, \"data\\mnist.npz\")\n",
        "# mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# Discard test set\n",
        "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n",
        "        \n",
        "# Normalize pixel values\n",
        "x_train = x_train / 255.0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now take a look at the shape of the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 60000 examples with shape (28, 28)\n"
          ]
        }
      ],
      "source": [
        "data_shape = x_train.shape\n",
        "\n",
        "print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Defining your callback\n",
        "Now it is time to create your own custom callback. For this complete the myCallback class and the on_epoch_end method in the cell below. If you need some guidance on how to proceed, check out this link."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GRADED CLASS: myCallback\n",
        "### START CODE HERE\n",
        "\n",
        "# Remember to inherit from the correct class\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "        # Define the correct function signature for on_epoch_end\n",
        "        def on_epoch_end(self, epoch, logs = {}):\n",
        "            if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99:\n",
        "                print(\"\\nReached 99% accuracy so cancelling training!\") \n",
        "                \n",
        "                # Stop training once the above condition is met\n",
        "                self.model.stop_training = True\n",
        "\n",
        "### END CODE HERE"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create and train your model\n",
        "Now that you have defined your callback it is time to complete the train_mnist function below.\n",
        "\n",
        "**You must set your model to train for 10 epochs and the callback should fire before the 9th epoch for you to pass this assignment.**\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "Feel free to try the architecture for the neural network that you see fit but in case you need extra help you can check out an architecture that works pretty well at the end of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: train_mnist\n",
        "def train_mnist(x_train, y_train):\n",
        "\n",
        "    ### START CODE HERE\n",
        "    \n",
        "    # Instantiate the callback class\n",
        "    callbacks = myCallback()\n",
        "    \n",
        "    # Define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
        "        tf.keras.layers.Dense(512, activation = tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "    ]) \n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', \n",
        "                  loss='sparse_categorical_crossentropy', \n",
        "                  metrics=['accuracy']\n",
        "                  ) \n",
        "    \n",
        "    # Fit the model for 10 epochs adding the callbacks\n",
        "    # and save the training history\n",
        "    history = model.fit(x_train, y_train, epochs = 10, callbacks = [callbacks])\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return history"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Call the train_mnist passing in the appropiate parameters to get the training history:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1999 - accuracy: 0.9395\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0804 - accuracy: 0.9753\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0531 - accuracy: 0.9829\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0371 - accuracy: 0.9881\n",
            "Epoch 5/10\n",
            "1857/1875 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9912\n",
            "Reached 99% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0272 - accuracy: 0.9912\n"
          ]
        }
      ],
      "source": [
        "hist = train_mnist(x_train, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you see the message Reached 99% accuracy so cancelling training! printed out after less than 9 epochs it means your callback worked as expected.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Congratulations on finishing this week's assignment!**\n",
        "\n",
        "You have successfully implemented a callback that gives you more control over the training loop for your model. Nice job!\n",
        "\n",
        "**Keep it up!**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Exercise2-Question.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
